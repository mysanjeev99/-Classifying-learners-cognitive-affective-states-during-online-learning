{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPROVED MODEL WEBCAM DEPLOYMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from keras import models\n",
    "from keras.models import model_from_json\n",
    "from facenet_pytorch import MTCNN\n",
    "mtcnn = MTCNN(margin=20, keep_all=True, post_process=False, device='cuda:0')\n",
    "import mediapipe as mp # Import mediapipe\n",
    "import cv2 # Import opencv\n",
    "\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing helpers\n",
    "mp_holistic = mp.solutions.holistic # Mediapipe Solutions\n",
    "\n",
    "\n",
    "video = cv2.VideoCapture(0)\n",
    "prev_frame_time = 0\n",
    "new_frame_time = 0\n",
    "\n",
    "\n",
    "model_name = \"model_main2_WORKING\"\n",
    "FPS_CAP=10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# load json and create model\n",
    "json_file = open(model_name+'/model.json', 'r') \n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "model.load_weights(model_name+\"/model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "class_names = {0 : 'BORED', 1: 'CONFUSED', 2 : 'DELIGHT', 3 : 'FRUSTRATED', 4 : 'NEUTRAL'}\n",
    "C_FPS = 0\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5,model_complexity =0) as holistic:\n",
    "        \n",
    "        while True:\n",
    "                _, frame = video.read()\n",
    "                new_frame_time = time.time()\n",
    "                fps = 1/(new_frame_time-prev_frame_time)\n",
    "                prev_frame_time = new_frame_time\n",
    "                fps = int(fps)\n",
    "                fps = str(fps)\n",
    "                C_FPS = C_FPS +1\n",
    "\n",
    "                #Convert the captured frame into RGB\n",
    "                im = Image.fromarray(frame, 'RGB')\n",
    "                \n",
    "                #Resizing into 160x160 because we trained the model with this image size.\n",
    "                #im = im.resize((160,160))\n",
    "                 \n",
    "                # Recolor Feed\n",
    "                image1 = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                image1.flags.writeable = False        \n",
    "                # Recolor image back to BGR for rendering\n",
    "                image1.flags.writeable = True   \n",
    "                image = cv2.cvtColor(image1, cv2.COLOR_RGB2BGR)\n",
    "                if C_FPS == FPS_CAP:\n",
    "                        faces = mtcnn(im)\n",
    "\n",
    "                        try:\n",
    "                                for im in faces:\n",
    "                                        # DL MODEL\n",
    "                                        im = im.permute(1,2,0)\n",
    "                                        img_array = np.expand_dims(im, axis=0)\n",
    "                                        prediction = model.predict(img_array,verbose = 0)\n",
    "                                        maxindex = int(np.argmax(prediction))\n",
    "                                        prediction = class_names[maxindex]\n",
    "\n",
    "                                        # Make Detections\n",
    "                                        results = holistic.process(image1)\n",
    "                                        # print(results.face_landmarks)\n",
    "\n",
    "                        except:\n",
    "                                prediction = \"NONE\"\n",
    "                        C_FPS = 0\n",
    "\n",
    "\n",
    "                try:\n",
    "                        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "                        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                                mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                                mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                                )\n",
    "\n",
    "                        # Left Hand\n",
    "                        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                                mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                                mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                                )\n",
    "\n",
    "                        # Pose Detections\n",
    "                        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                                )\n",
    "                        pose = results.pose_landmarks.landmark\n",
    "                        h1 = results.right_hand_landmarks.landmark\n",
    "                        h2 = results.left_hand_landmarks.landmark\n",
    "\n",
    "                except:\n",
    "                        _\n",
    "\n",
    "\n",
    "                try:\n",
    "                        if (pose[7].x-pose[3].x) < 0.01:\n",
    "                                #cv2.putText(image, (str(\"BORED\"+ \"{:.2f}\".format((pose[7].x-pose[3].x)))), (5, 190), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "                                prediction = \"BORED\"\n",
    "                        elif(pose[6].x-pose[8].x) < 0.01:\n",
    "                                #cv2.putText(image, (str(\"BORED\"+ \"{:.2f}\".format((pose[6].x-pose[8].x)))), (5, 190), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "                                prediction = \"BORED\"       \n",
    "                        else:\n",
    "                                #cv2.putText(image, (str(\"Not Distracted\"+ \"{:.2f}\".format((pose[7].x-pose[3].x)))), (5, 190), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "                                _ \n",
    "                        cv2.putText(image, str(prediction), (5, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "                except:\n",
    "                        _\n",
    "\n",
    "\n",
    "                cv2.putText(image, (\"FPS:\"+fps), (5, 80), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "                cv2.imshow(\"DETECTION\", image)\n",
    "                key=cv2.waitKey(1)\n",
    "                if key == ord('q'):\n",
    "                        break\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
