{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset download FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "dft = pd.read_csv('faceexp-comparison-data-train-public.csv', sep=',', header=None)\n",
    "dfv = pd.read_csv('faceexp-comparison-data-test-public.csv', sep=',', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft1 = dft[0].drop_duplicates()\n",
    "dft2 = dft[5].drop_duplicates()\n",
    "dft3 = dft[10].drop_duplicates()\n",
    "dftmc = pd.concat([dft1, dft2, dft3], axis=0)\n",
    "dftm = dftmc.drop_duplicates()\n",
    "\n",
    "dfv1 = dfv[0].drop_duplicates()\n",
    "dfv2 = dfv[5].drop_duplicates()\n",
    "dfv3 = dfv[10].drop_duplicates()\n",
    "dfvmc = pd.concat([dft1, dft2, dft3], axis=0)\n",
    "dfvm = dfvmc.drop_duplicates()\n",
    "\n",
    "\n",
    "df= pd.concat([dftm, dfvm], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162520/162520 [7:03:13<00:00,  6.40it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time: 25394.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time() #took 7.05 hrs\n",
    "i = 1\n",
    "for lnk in tqdm(df):\n",
    "    try:\n",
    "        urllib.request.urlretrieve(lnk, \"DOWN_FILES/\"+str(i)+\".jpg\")\n",
    "        i = i+1\n",
    "    except:\n",
    "        continue\n",
    "end = time.time()\n",
    "print(\"Total Time: {}\".format(round(end-start, 1)))\n",
    "# TIME TAKEN 7.05 hrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting face "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 151185/151185 [8:45:16<00:00,  4.80it/s]  \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADnCAYAAAC9roUQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAADKUlEQVR4nO3UMQEAIAzAMMC/5+GiHCQKenXPzAKgcV4HAPzEdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIGS6ACHTBQiZLkDIdAFCpgsQMl2AkOkChEwXIHQBcjcEy3+fc28AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir = \"./DOWN_FILES/\"\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from facenet_pytorch import MTCNN\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "eye_cascade = cv2.CascadeClassifier(f\"{cv2.data.haarcascades}haarcascade_eye.xml\")\n",
    "mouth_cascade = cv2.CascadeClassifier(f\"haarcascade_mcs_mouth.xml\")\n",
    "img_file = []\n",
    "i = 1\n",
    "for file in tqdm(os.listdir(dir)):\n",
    "    mtcnn = MTCNN(margin=20, keep_all=True, post_process=False, device='cuda:0')\n",
    "    img = Image.open(\"./DOWN_FILES/\"+file)\n",
    "    try:\n",
    "        faces = mtcnn(img)\n",
    "        try:\n",
    "            for face in faces:\n",
    "                laplacian_var = cv2.Laplacian((face.permute(1, 2, 0).int().numpy()).astype(np.uint8), cv2.CV_64F).var()\n",
    "                if laplacian_var < 9:\n",
    "                    continue\n",
    "                else:\n",
    "                    detected_eye = eye_cascade.detectMultiScale((face.permute(1, 2, 0).int().numpy()).astype(np.uint8))\n",
    "                    if len(detected_eye) != 0:\n",
    "                        detected_mouth = mouth_cascade.detectMultiScale((face.permute(1, 2, 0).int().numpy()).astype(np.uint8))\n",
    "                        if len(detected_mouth) != 0:\n",
    "                            plt.axis('off')\n",
    "                            plt.imsave('./JUST_FACE_EXTRACTED/'+str(i)+'.png',(face.permute(1, 2, 0).int().numpy()).astype(np.uint8))\n",
    "                            i = i + 1\n",
    "                        else:\n",
    "                            continue\n",
    "                    else:\n",
    "                        continue\n",
    "        except:\n",
    "            continue\n",
    "    except:\n",
    "        continue\n",
    "# TIME TAKEN 8:45 hrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refine Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"./DOWN_FILES/\"\n",
    "import glob\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from facenet_pytorch import MTCNN\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "eye_cascade = cv2.CascadeClassifier(f\"{cv2.data.haarcascades}haarcascade_eye.xml\")\n",
    "mouth_cascade = cv2.CascadeClassifier(f\"haarcascade_mcs_mouth.xml\")\n",
    "img_file = []\n",
    "i = 1\n",
    "for file in tqdm(os.listdir(dir)):\n",
    "    #img = Image.open(\"./DOWN_FILES/\"+file)\n",
    "    img = cv2.imread(\"./DOWN_FILES/\"+file)\n",
    "    name, _= os.path.splitext(file)\n",
    "    try:\n",
    "        detected_eye = eye_cascade.detectMultiScale(img)\n",
    "        if len(detected_eye) != 0:\n",
    "            detected_mouth = mouth_cascade.detectMultiScale(img)\n",
    "            if len(detected_mouth) != 0:\n",
    "                plt.axis('off')\n",
    "                shutil.copy(\"./DOWN_FILES/\"+file, \"./JUST_FACE_EXTRACTED/\"+file)\n",
    "                i = i + 1\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            continue\n",
    "    except:\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
